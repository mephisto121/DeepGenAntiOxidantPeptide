{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\anaconda\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "f:\\anaconda\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "f:\\anaconda\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from vocab import Vocab\n",
    "from helper_functions import *\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=23\n",
    "batch_size=64\n",
    "embedding_dim=256\n",
    "rnn_units=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_General_data = pd.read_csv(\"data\\general_peptide_data.csv\")\n",
    "vocabulary, _ = Vocab.create_vocab(np.array(df_General_data.Sequence.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'!': 1, 'G': 8, 'D': 5, 'V': 20, 'K': 11, 'F': 7, 'S': 18, 'L': 12, '%': 2, 'H': 9, 'N': 14, 'Y': 22, 'I': 10, 'E': 6, 'Q': 16, 'C': 4, 'R': 17, 'W': 21, 'P': 15, 'A': 3, 'T': 19, 'M': 13, '+': 0}\n"
     ]
    }
   ],
   "source": [
    "vocab = vocabulary.vocab\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x11d87807550>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.keras.Input(shape=(None,), batch_size = 1)\n",
    "x2 = tf.keras.layers.Embedding(\n",
    "    input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True\n",
    ")(x)\n",
    "h1 = layers.GRU(rnn_units, return_sequences=True, stateful=True)(x2)\n",
    "h2 = layers.GRU(rnn_units, return_sequences=True, stateful=True)(h1)\n",
    "\n",
    "yhat = tf.keras.layers.Dense(vocab_size)(h2)\n",
    "inference_model = tf.keras.Model(inputs=x, outputs=yhat)\n",
    "inference_model.load_weights(\"GRU_TL\\checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(1, None)]               0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (1, None, 256)            5888      \n",
      "                                                                 \n",
      " gru (GRU)                   (1, None, 256)            394752    \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (1, None, 256)            394752    \n",
      "                                                                 \n",
      " dense (Dense)               (1, None, 23)             5911      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 801,303\n",
      "Trainable params: 801,303\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inference_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pep_gen_base = Generate(inference_model,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [5:31:23<00:00,  2.51it/s]  \n"
     ]
    }
   ],
   "source": [
    "generated_seqs = pep_gen_base.generate_multi_seqs(50000,8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_df = pd.DataFrame(generated_seqs, columns = [\"generated_seqs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_df.to_pickle(\"data/Generated_unfilter.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_df.to_csv(\"data/Generated_unfilter.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec3b6344b8b3f6c3db1463248c46b8920f4fc68f6187e2c1e71f56a52299e245"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
