{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiuuqBYE3hSS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn import metrics\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import KFold\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.metrics import AUC, Accuracy, Precision\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras.metrics import Precision\n",
        "from tensorflow.keras.models import Model\n",
        "from helper_functions import get_model_name\n",
        "from vocab import Vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJtTqELj4M0I"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(\"/data/Classification_data.csv\")\n",
        "Seq = []\n",
        "labels = []\n",
        "\n",
        "for i, seq in enumerate(train_data.Sequence):\n",
        "\n",
        "    if train_data['Chelator'][i] == 0 and train_data[\"FRS\"][i] ==1:\n",
        "        if 1<len(train_data[\"Sequence\"][i]) <=20:\n",
        "            Seq.append(train_data[\"Sequence\"][i])\n",
        "            labels.append(1)\n",
        "\n",
        "    elif train_data['Chelator'][i]==1 and train_data['FRS'][i] == 1:\n",
        "        if 1<len(train_data[\"Sequence\"][i]) <=20:\n",
        "            Seq.append(train_data[\"Sequence\"][i])\n",
        "            labels.append(1)\n",
        "\n",
        "    elif train_data['Chelator'][i] == 0 and train_data['FRS'][i] == 0:\n",
        "        if 1<len(train_data[\"Sequence\"][i]) <=20:\n",
        "            Seq.append(train_data[\"Sequence\"][i])\n",
        "            labels.append(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJw0CR4d40Se"
      },
      "outputs": [],
      "source": [
        "Xdata = np.array(Seq)\n",
        "Ydata = np.array(labels)\n",
        "\n",
        "Xdata, Ydata = shuffle(Xdata, Ydata, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYnrPKU66EBf"
      },
      "outputs": [],
      "source": [
        "text_vectorizer = TextVectorization(\n",
        "                                    standardize=None,\n",
        "                                    split =\"character\",\n",
        "                                    output_mode='int'\n",
        "                                    )\n",
        "text_vectorizer.adapt(Xdata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qT_p-kZg9XBa"
      },
      "outputs": [],
      "source": [
        "def model():\n",
        "    tf.random.set_seed(42)\n",
        "    input = layers.Input(shape=(1,), dtype=\"string\")\n",
        "    vect = text_vectorizer(input)\n",
        "    x1 = layers.Embedding(22, 256)(vect)\n",
        "    x2 = layers.Conv1D(128,3)(x1)\n",
        "    x3 = layers.GlobalMaxPooling1D()(x2)\n",
        "    layer1 = tf.keras.layers.LayerNormalization(axis=-1)\n",
        "    xx = layer1(x3)\n",
        "    yhat = layers.Dense(1, activation = \"sigmoid\")(xx)\n",
        "    classification_model = Model(inputs = input, outputs = yhat)\n",
        "    return classification_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PolefCZo9Z8S"
      },
      "outputs": [],
      "source": [
        "epochs = 80\n",
        "batch_size = 10\n",
        "\n",
        "name = \"crossval\"\n",
        "n_splits=5\n",
        "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "accuracy = []\n",
        "auc = []\n",
        "precision = []\n",
        "fold_no = 1\n",
        "for train, test  in kfold.split(Xdata, Ydata):\n",
        "    train_model = model()\n",
        "    rlr = ReduceLROnPlateau(monitor='val_auc', factor=0.5,patience=5, min_lr=0.000001, verbose=1, min_delta=1e-5)\n",
        "    train_model.compile(optimizer = tf.keras.optimizers.legacy.Adam(learning_rate = 0.0003,decay = 0.001),\n",
        "                                loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                                metrics = ['accuracy', tf.keras.metrics.AUC(), Precision()])\n",
        "    print(f'training fold number {fold_no}')\n",
        "\n",
        "    save_dir = 'Classification_model/'\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(fold_no, name),\n",
        "            monitor='val_accuracy', verbose=1,\n",
        "            save_best_only=True, mode='max')\n",
        "\n",
        "    callbacks_list = [checkpoint, rlr]\n",
        "\n",
        "    history = train_model.fit(Xdata[train], Ydata[train], epochs = epochs,\n",
        "                            validation_data = (Xdata[test], Ydata[test]),\n",
        "                            batch_size = batch_size,\n",
        "                            callbacks = callbacks_list)\n",
        "\n",
        "\n",
        "    train_model.load_weights(save_dir+get_model_name(fold_no, name))\n",
        "    scores = train_model.evaluate(Xdata[test], Ydata[test], verbose=0)\n",
        "    accuracy.append(scores[1])\n",
        "    auc.append(scores[2])\n",
        "    precision.append(scores[3])\n",
        "    y_pred = train_model.predict(Xdata[test])\n",
        "    tf.keras.backend.clear_session()\n",
        "    fold_no+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o8GmW9__YjS",
        "outputId": "00336a1e-26a9-430a-be2b-05e242fbf62c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "score per fold:\n",
            "Accuracy in fold 1: 77.8181791305542, \n",
            "AUC in fold 1: 83.04196000099182,\n",
            " Precision in fold1: 79.71014380455017\n",
            "Accuracy in fold 2: 77.0909070968628, \n",
            "AUC in fold 2: 83.80423188209534,\n",
            " Precision in fold2: 74.52229261398315\n",
            "Accuracy in fold 3: 77.0909070968628, \n",
            "AUC in fold 3: 83.02387595176697,\n",
            " Precision in fold3: 76.37795209884644\n",
            "Accuracy in fold 4: 74.45255517959595, \n",
            "AUC in fold 4: 81.0380756855011,\n",
            " Precision in fold4: 77.66990065574646\n",
            "Accuracy in fold 5: 75.91241002082825, \n",
            "AUC in fold 5: 82.31560587882996,\n",
            " Precision in fold5: 74.40000176429749\n"
          ]
        }
      ],
      "source": [
        "print(\"score per fold:\")\n",
        "for i in range(n_splits):\n",
        "    print(f'Accuracy in fold {i+1}: {accuracy[i]*100}, \\nAUC in fold {i+1}: {auc[i]*100},\\n Precision in fold{i+1}: {precision[i]*100}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yiv9Keuk_brN",
        "outputId": "07746350-054b-498f-b961-d36ba49dc7d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy: 76.4729917049408,\n",
            "Average AUC: 82.64474987983704,\n",
            " Average Precision: 76.53605818748474\n"
          ]
        }
      ],
      "source": [
        "print(f\"Average Accuracy: {sum(accuracy)/5 *100},\\nAverage AUC: {sum(auc)/5 *100},\\n Average Precision: {sum(precision)/5 *100}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYSEdNGRLswx",
        "outputId": "c2a1d7d3-25fb-4c42-bda9-b6d9c509ea7a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _xla_gc_callback at 0x7b30857eacb0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 97, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 10ms/step\n",
            "MCC for Fold 1: 0.5566673715036466\n",
            "9/9 [==============================] - 0s 8ms/step\n",
            "MCC for Fold 2: 0.5448356265763565\n",
            "9/9 [==============================] - 0s 9ms/step\n",
            "MCC for Fold 3: 0.5400313689369748\n",
            "9/9 [==============================] - 0s 9ms/step\n",
            "MCC for Fold 4: 0.4874453575400174\n",
            "9/9 [==============================] - 0s 6ms/step\n",
            "MCC for Fold 5: 0.5152038765644379\n",
            "Average MCC: 0.5288367202242866\n"
          ]
        }
      ],
      "source": [
        "# Load the models into a list\n",
        "models = []\n",
        "for i in range(1, 6):\n",
        "    model_path = f'/Classification_model/model_crossval{i}.tf'\n",
        "    model = tf.keras.models.load_model(model_path, custom_objects={'Precision': Precision, 'AUC': AUC, 'accuracy': Accuracy})\n",
        "    models.append(model)\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "mcc = []\n",
        "\n",
        "for fold_index, (train_indices, test_indices) in enumerate(kfold.split(Xdata, Ydata)):\n",
        "    X_train, X_test = Xdata[train_indices], Xdata[test_indices]\n",
        "    y_train, y_test = Ydata[train_indices], Ydata[test_indices]\n",
        "\n",
        "    # Get the corresponding model for the current fold\n",
        "    model = models[fold_index]\n",
        "\n",
        "    # Make predictions using the current model\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    # Convert predictions to binary values\n",
        "    binary_predictions = (predictions >= 0.5).astype(int).reshape(predictions.shape[0])\n",
        "\n",
        "    # Calculate the Matthews correlation coefficient\n",
        "    mcc_fold = metrics.matthews_corrcoef(y_test, binary_predictions)\n",
        "    mcc.append(mcc_fold)\n",
        "\n",
        "    print(f\"MCC for Fold {fold_index + 1}: {mcc_fold}\")\n",
        "\n",
        "# Calculate the average MCC\n",
        "average_mcc = sum(mcc) / len(mcc)\n",
        "print(f\"Average MCC: {average_mcc}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
